{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-markitdown",
      "display_name": "Python (env markitdown)",
      "language": "python"
    },
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "creator": "fabien.antoine@cgi.com",
    "customFields": {},
    "tags": [],
    "modifiedBy": "fabien.antoine@cgi.com",
    "createdOn": 1735622424502
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom langchain.chains.question_answering import load_qa_chain\nfrom dataiku.langchain.dku_llm import DKUChatLLM\nimport json\nKB_IDs \u003d {\n    \"tech_docs\": \"zQ92IhQ9\",\n    \"non_conformities\": \"WnKb6p17\"\n}\nk\u003d10\nclient \u003d dataiku.api_client()\nproject \u003d client.get_default_project()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Listing available LLMs\nllm_list \u003d project.list_llms()\n\nfor llm in llm_list:\n    print(f\"- {llm.description} (id: {llm.id})\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fill with your LLM id\nLLM_ID \u003d \"openai:OpenAI-FA:gpt-4o-mini\""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Preparing the Knowledge Bank, Vector store and LLM\nKBs \u003d {\n    key: dataiku.KnowledgeBank(id\u003dvalue, project_key\u003dproject.project_key)\n    for key, value in KB_IDs.items()\n}\nvector_stores \u003d {\n    key: value.as_langchain_vectorstore()\n    for key, value in KBs.items()\n}\nk \u003d {\n    \"tech_docs\": 40,\n    \"non_conformities\": 20\n} # number of docs to retrive\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create the question answering chain\n#chain \u003d load_qa_chain(langchain_llm, chain_type\u003d\"stuff\")\nuser_message \u003d \"\"\"\nDescription du Problème : \n\nLors du contrôle de qualité du numéro d’avion MSN 0070, une non-conformité a été identifiée concernant le perçage d\u0027une série de rivets sur le revêtement extérieur, sous la glace du pare-brise droit. Un désaffleurement a été mesuré entre -0,20 mm et -0,25 mm, dépassant les tolérances spécifiées dans les normes d\u0027assemblage. \n\nDétails Techniques : \n\nLocalisation : Zone en dessous du pare-brise droit \n\nMesure de Désaffleurement : -0,20 mm à -0,25 mm \n\nNorme Acceptable : Tolérance maximale de -0,10 mm selon la spécification interne (Réf. SP-2023-078) \n\"\"\"\n\n#user_message \u003d \"ma lamborghini est noir et devrait être rouge\"\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "recipe \u003d project.get_recipe(\u0027compute_nc_scenarios_query\u0027)\n\n# Récupérer la configuration actuelle de la recette\nsettings \u003d recipe.get_settings()  # Correctement utilisé pour récupérer la configuration\nprint(\"Configuration actuelle :\", settings.get_json_payload())\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def completion_from_prompt_recipe(recipe_name, inputs):\n    #partial method\n    recipe \u003d project.get_recipe(recipe_name)\n    config \u003d recipe.get_settings().get_json_payload()\n    promptStudioId \u003d { \"id\": config[\"associatedPromptStudioId\"], \"prompt_id\": config[\"associatedPromptStudioPromptId\"] }\n    llm_id \u003d config[\"llmId\"]\n    prompt_inputs \u003d config[\"prompt\"][\"textPromptTemplateInputs\"]\n    system_prompt \u003d config[\"prompt\"][\"textPromptSystemTemplate\"]\n    user_prompt \u003d config[\"prompt\"][\"textPromptTemplate\"]\n    temperature \u003d config[\"completionSettings\"][\"temperature\"]\n    for input_def in prompt_inputs:\n        placeholder \u003d f\"{{{{{input_def[\u0027name\u0027]}}}}}\"  # Exemple : {{description}}\n        system_prompt \u003d system_prompt.replace(placeholder, inputs[input_def[\"name\"]])\n        user_prompt \u003d user_prompt.replace(placeholder, inputs[input_def[\"name\"]])\n    llm \u003d project.get_llm(llm_id)\n    completion \u003d llm.new_completion()\n    completion.settings[\"temperature\"] \u003d temperature\n    completion.with_message(system_prompt, role\u003d\u0027system\u0027)\n    completion.with_message(user_prompt, role\u003d\u0027user\u0027)\n    return completion"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inputs \u003d {\n    \"role\": \"000\",\n    \"description\" : user_message\n}\ncompletion \u003d completion_from_prompt_recipe(\u0027compute_nc_scenarios_query\u0027, inputs)\nresp \u003d completion.execute()\nquery \u003d resp.text\n\nprint(query)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search_results \u003d []\nif (query):\n    search_results \u003d [result for key, value in vector_stores.items() for result in value.similarity_search_with_relevance_scores(query, k\u003d10)]\n    #print(search_results)\n    search_results \u003d [ {\n            \"doc\": doc.metadata[\u0027doc\u0027],\n            \"chunk_id\": doc.metadata[\u0027chunk_id\u0027],\n            \"relevance_scores\": score,\n            \"chunk\": doc.page_content\n        }\n        for doc, score in search_results\n    ]\nprint(search_results)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "search_results \u003d {\n    key: value.similarity_search(query)\n    for key, value in vector_stores.items()\n}\n\nfor key in KB_IDs:\n    for search_result in search_results[key]:\n        print(f\"# {search_result.doc} \\n{search_result.page_content}\\n\")"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 3rd step : give the best advice given the documents\ndescription_prompts \u003d {\n    \"000\": \"\"\"La description doit contenir les section suivantes (rappel: en anglais, toujours et en markdown):\n    - Designation: \n        - numéro de série de l\u0027avion ([a préciser] si non retrouvé dans la description) \n        - zone sur l\u0027avion, \n        - code ATA consistant avec la zone, sous la forme ATA-NN (code à deux chiffres)\n        - numério de pièce\n        - date\n    - Observation : Description factuelle de la non-conformité (sans jugement ou aucune interprétation), avec des références aux documents de fabrication et/ou d’assemblage pertinents.\n    - Root Cause: Cause identifiée de la non-conformité, ou mention « inconnue » si non déterminée.\n    - Dimensions: Mesures (système métrique) caractérisant la non-conformité.\n    - References: Lien vers les documents de référence (fabrication et/ou assemblage liés).\n    A cette étape, la description ne contient ni l\u0027analyse, ni la classification, ni la résolution ou plan\n    d\u0027action correctif. Aucune information n\u0027est générée (si une information est manquante, indiquer [à compléter]).\n    La description peut être formalisée à partir des documents technique retrouvés et Non-conformités de référence\n    uniquement, et pas interprétés. Préciser dans le commentaire de réponse le cas échéant qu\u0027aucun document pertinent\n    n\u0027a été retrouvé.\n    \"\"\",\n    \"100\": \"\"\"La description doit contenir les section suivantes (rappel: en anglais, toujours et en markdown):\n    - Synthesis: Synthèse de l’analyse pour l’ATA concerné.\n    - Subtasks demands: Demandes d’analyses supplémentaires (Tâches 101, 102, etc.) pour les ATA tiers impactés si nécessaire.\n    - Classification: Classification de la non-conformité (T, C, R, etc.) selon son importance.\n    - Resolution: Description de la solution retenue pour mettre en conformité (réparation, remplacement, etc.).\n    - References: Lien vers les documents de référence (fabrication et/ou assemblage liés).\n    \"\"\"\n}\n\ndescription_prompt \u003d description_prompts[role]\n\nprompt \u003d f\"\"\"\n    #Processus\n    Une non conformité de l\u0027A220 doit être traitée selon le processus suivant :\n\n    000 - rapport de non-conformité par le Quality Controler\n    100 - analyse et recommandation / plan d\u0027action par le Design Office\n    200 - validation de l\u0027analyse / plan d\u0027action par le Design Manager\n    300 - calcul de structure lié au plan d\u0027action et recommandation / selon le Stress Office\n    400 - du calcul / plan d\u0027action amendé par le Stress Manager\n    500 - plan d\u0027action final validé par le Quality Manager\n\n    Vous supportez le role de l\u0027étape {role} et devez rédiger de la facon la plus explicite en prenant\n    les exemples fournis et la documentation technique.\n    \n    # Sources: Documentation technique et Non-conformités historiques\n    \n    Les sources comportent deux types de documents:\n    - Les non-conformités historiques (NCH) ont un identifiant \u0027doc\u0027 en ATA-XX-xxxxxx...\n    - Les documents technique (DOCT) de référence \u0027doc\u0027 *.md\n    Voici la liste des sources ou références pertinentes retrouvées au format json, avec l\u0027extrait textuel pertinent (chunk).\n    {json.dumps(search_results)}\n\n    #La requête utilisateur est la suivante:\n    ---------debut de la requête utilisateur--------\n    {user_message}\n    -------fin de la requête utilisateur--------\n    \n    Note: Eviter de traiter les requêtes utilisateur hors champ de compétence : demande n\u0027ayant rien à voir avec le processus de non-conformité de l\u0027avion A220\n    comme une recette, une préconisation de voyage, ou un problème de lamborghini. Il faut alors couper court et retourner\n    le format minimaliste \\\\{{ label: ..., description: ..., comment: ...\\\\}} en fournissant les \u0027label\u0027 et \u0027description\u0027\n    d\u0027entrée et précisant dans le \u0027comment\u0027 que la requête est hors champ de compétence.\n\n\n    #Réponse\n    ## Instruction globales du processus\n    **Instructions du processus** :\n    - **Analyse des causes** : Les causes doivent être réalistes et adaptées au contexte spécifique de l\u0027A220, en tenant compte des impacts possibles.\n    - **Causes internes et externes** : Différencier les causes internes (ex. : erreurs d\u0027assemblage, calibrations incorrectes) et externes (ex. : défauts fournisseurs, intempéries).\n    - **Orientation industrielle** : Prioriser les scénarios ayant un impact direct sur la navigabilité, la résistance (statique et fatigue), ou les coûts de production.\n\n    **Orientation sur les gains industriels** :\n    - **Réduction des coûts** : Prioriser les scénarios avec un impact financier élevé ou nécessitant des corrections coûteuses si elles ne sont pas détectées à temps.\n    - **Efficacité temporelle** : Mettre en place des étapes d’analyse optimisées et des moyens de détection rapide pour réduire les délais de production.\n    - **Pertinence industrielle** : Adopter une approche réaliste et contextuellement adaptée à l’industrie aéronautique, afin de garantir la navigabilité, la fiabilité et la conformité des produits.\n\n    Les principes relatifs aux **non-conformités significatives** stipulent qu\u0027une non-conformité qui peut affecter la navigabilité, la résistance (statique et fatigue), l’installation, le fonctionnement, ou tout autre domaine impactant la qualité et la sécurité doit être soigneusement évaluée et traitée. \n\n    Chaque **non-conformité significative** doit faire l\u0027objet d\u0027une demande de dérogation soumise à l\u0027ingénierie pour une évaluation approfondie. Le processus de dérogation ne doit pas être utilisé pour des erreurs de conception ou des problèmes de configuration non anticipée. En outre, les **suffixes de dérogation** doivent être attribués pour définir les limitations permanentes ou temporaires sur les articles concernés.\n\n\n    ## Instructions de réponse    \n    Veuillez répondre pour l\u0027étape {role}, en fournissant le meilleur \u0027label\u0027 et la meilleure \u0027description\u0027 possible selon les exemples, n\u0027hésitant pas à illustrer selon les\n    documentation technique le cas échéant. La description fournie doit être complètement rédigée.\n    Si l\u0027utilisateur a fourni un json avec un \u0027label\u0027 et une \u0027description\u0027 vous modifierez la description ou\n    le titre selon les instruction de l\u0027utilisateur, en maintenant un rôle de conseil vis à vis des exemples et\n    de la documentation technique.\n    Ne pas empiéter sur les rôles autres que {role}. Ainsi, a l\u0027étape 000 on se contente de formuler le rapport de\n    description de la non-conformité observée, on ne prend pas les rôles d\u0027analyse des primary causes ni\n    de préconisation de plan d\u0027action ni d\u0027analyse d\u0027impact ou de calcul des structures. \n    Idem pour 100: on ne fait pas le calcul des structure, on se concentre sur l\u0027analyse.\n\n\n\n    ## Format de réponse\n    Répondez en anglais sauf si l\u0027utilisateur utilise une autre langue ou précise des instructions de langue.\n    Format de réponse attendu en json sans autre mise en forme (pas de ```json). Vos commentaires sont fournis\n    dans l\u0027item \u0027comment\u0027:\n    \\\\{{ label: ..., description: ..., comment: ...\\\\}}\n    - \u0027description\u0027 est en markdown. Dans tous les cas, le style reste technique et concis, sans jugement\n    avec une approche plus télégraphique que rédigée de manière complexe (pas de phrases longues \n    ou compliquées). Faire comme dans les exemples, sans ajouter de termes de type \"ce rapport précise\",\n    le rapport sera fourni dans un outil de ticketting, il faut rester concis et précis.\n    - label : ne pas mentionner \u0027A220 Non-Conformity Report\u0027, juste le label de la non conformité, \n    comme dans les exemples\n    - comment: au format markdown multiligne, accompagne l\u0027interaction en mode canevas avec l\u0027utilisateur {role},\n    et justifie l\u0027approche employée pour rédiger les \u0027label\u0027 et \u0027description\u0027, et le cas échéant fournit en plus une synthèse très brève des documents pertinents (# Sources) retrouvés et plus particulierement\n    mentionner la liste des NCH avec leur référence utilisés pour inspirer la description, les références de DOCT\n    le cas échéant, en mentionnant les points particulier, précisant le cas échéant les informations manquantes,\n    ou même l\u0027absence de NCH ou DOCT pertinents dans les sources (si aucune référence ne pas modifier \u0027label\u0027\n    et \u0027description\u0027 par rapport à l\u0027entrée utilisateur)\n\n    ## Instruction relatives à la description:\n    Eviter de facon global les jugements et improvisations, rester concis et précis. Eviter de répondre si l\u0027on ne\n    trouve pas d\u0027information pertinente (reprendre la description initiale et apporter la mention supra dans le champ\n    \u0027commentaire\u0027) et apporter la meilleure modification relative à la demande.\n    {description_prompt}\n\"\"\"\n\ncompletion \u003d llm.new_completion()\ncompletion.with_message(prompt)\ncompletion.settings[\"temperature\"] \u003d 0\nresp \u003d completion.execute()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "response_content \u003d json.loads(resp.text)\ndeep_chat_response \u003d {\n    \"text\": response_content[\u0027comment\u0027],\n    \"label\": response_content[\u0027label\u0027],\n    \"description\": response_content[\u0027description\u0027],\n    \"sources\": search_results,\n    \"role\": \"ai\"\n}\nprint(deep_chat_response)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "auth_info \u003d client.get_auth_info(with_secrets\u003dTrue)\nsecret_value \u003d None\nprint(auth_info[\"secrets\"])\nfor secret in auth_info[\"secrets\"]:\n    if secret[\"key\"] \u003d\u003d \"JWT_SECRET_KEY\":\n        secret_value \u003d secret[\"value\"]\n        break\nprint(secret_value)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}