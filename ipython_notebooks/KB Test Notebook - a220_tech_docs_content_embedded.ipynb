{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-markitdown",
      "display_name": "Python (env markitdown)",
      "language": "python"
    },
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "customFields": {},
    "creator": "fabien.antoine@cgi.com",
    "modifiedBy": "fabien.antoine@cgi.com",
    "createdOn": 1735622424502,
    "tags": []
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom langchain.chains.question_answering import load_qa_chain\nfrom dataiku.langchain.dku_llm import DKUChatLLM\nimport json\nKB_IDs \u003d {\n    \"tech_docs\": \"zQ92IhQ9\",\n    \"non_conformities\": \"WnKb6p17\"\n}\n\nclient \u003d dataiku.api_client()\nproject \u003d client.get_default_project()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Listing available LLMs\nllm_list \u003d project.list_llms()\n\nfor llm in llm_list:\n    print(f\"- {llm.description} (id: {llm.id})\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fill with your LLM id\nLLM_ID \u003d \"openai:OpenAI-FA:gpt-4o-mini\""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Preparing the Knowledge Bank, Vector store and LLM\nKBs \u003d {\n    key: dataiku.KnowledgeBank(id\u003dvalue, project_key\u003dproject.project_key)\n    for key, value in KB_IDs.items()\n}\nvector_stores \u003d {\n    key: value.as_langchain_vectorstore()\n    for key, value in KBs.items()\n}\n\ngpt_lc \u003d DKUChatLLM(llm_id\u003dLLM_ID, temperature\u003d0)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create the question answering chain\nchain \u003d load_qa_chain(gpt_lc, chain_type\u003d\"stuff\")\nquery \u003d \"Fuel Voltage Levels Quality\"\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search_results \u003d [result for key, value in vector_stores.items() for result in value.similarity_search(query)]\nsearch_results \u003d [ {\n        \"doc\": s.metadata[\u0027doc\u0027],\n        \"chunk_id\": s.metadata[\u0027chunk_id\u0027],\n        \"chunk\": s.page_content\n    }\n    for s in search_results\n]\nprint(search_results)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": false
      },
      "source": [
        "search_results \u003d {\n    key: value.similarity_search(query)\n    for key, value in vector_stores.items()\n}\n\nfor key in KB_IDs:\n    for search_result in search_results[key]:\n        print(f\"# {search_result.doc} \\n{search_result.page_content}\\n\")"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(dict(search_result))"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ⚡ Get the results ⚡\nresp \u003d chain({\"input_documents\":search_results, \"question\": query})\nprint(resp[\"output_text\"])"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}