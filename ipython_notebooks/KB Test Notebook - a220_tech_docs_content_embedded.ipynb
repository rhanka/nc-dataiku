{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-markitdown",
      "display_name": "Python (env markitdown)",
      "language": "python"
    },
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "creator": "fabien.antoine@cgi.com",
    "customFields": {},
    "tags": [],
    "modifiedBy": "fabien.antoine@cgi.com",
    "createdOn": 1735622424502
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom langchain.chains.question_answering import load_qa_chain\nfrom dataiku.langchain.dku_llm import DKUChatLLM\nimport json\nKB_IDs \u003d {\n    \"tech_docs\": \"zQ92IhQ9\",\n    \"non_conformities\": \"WnKb6p17\"\n}\nk\u003d10\nclient \u003d dataiku.api_client()\nproject \u003d client.get_default_project()\nagents \u003d {\n    \"query\": \"compute_nc_scenarios_query\",\n    \"nc_search\": \"compute_nc_scenarios_search_nc\",\n    \"doc_search\": \"compute_nc_scenarios_search_techdocs\",\n    \"000\": \"compute_nc_scenarios_propose_000\",\n    \"propose_000\": \"compute_nc_scenarios_propose_000\",\n    \"propose_100\": \"compute_nc_scenarios_propose_100\",\n    \"100\": \"compute_nc_scenarios_propose_100\"\n}"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Listing available LLMs\nllm_list \u003d project.list_llms()\n\nfor llm in llm_list:\n    print(f\"- {llm.description} (id: {llm.id})\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fill with your LLM id\nLLM_ID \u003d \"openai:OpenAI-FA:gpt-4o-mini\""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Preparing the Knowledge Bank, Vector store and LLM\nKBs \u003d {\n    key: dataiku.KnowledgeBank(id\u003dvalue, project_key\u003dproject.project_key)\n    for key, value in KB_IDs.items()\n}\nvector_stores \u003d {\n    key: value.as_langchain_vectorstore()\n    for key, value in KBs.items()\n}\nk \u003d {\n    \"tech_docs\": 40,\n    \"non_conformities\": 20\n} # number of docs to retrive\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create the question answering chain\n#chain \u003d load_qa_chain(langchain_llm, chain_type\u003d\"stuff\")\nuser_message \u003d \"\"\"\nDescription du Problème : \n\nLors du contrôle de qualité du numéro d’avion MSN 0070, une non-conformité a été identifiée concernant le perçage d\u0027une série de rivets sur le revêtement extérieur, sous la glace du pare-brise droit. Un désaffleurement a été mesuré entre -0,20 mm et -0,25 mm, dépassant les tolérances spécifiées dans les normes d\u0027assemblage. \n\nDétails Techniques : \n\nLocalisation : Zone en dessous du pare-brise droit \n\nMesure de Désaffleurement : -0,20 mm à -0,25 mm \n\nNorme Acceptable : Tolérance maximale de -0,10 mm selon la spécification interne (Réf. SP-2023-078) \n\"\"\"\n\n#user_message \u003d \"ma lamborghini est noir et devrait être rouge\"\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "recipe \u003d project.get_recipe(\u0027compute_nc_scenarios_query\u0027)\n\n# Récupérer la configuration actuelle de la recette\nsettings \u003d recipe.get_settings()  # Correctement utilisé pour récupérer la configuration\nprint(\"Configuration actuelle :\", settings.get_json_payload())\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def exec_prompt_recipe(recipe_name, inputs):\n    #partial method\n    recipe \u003d project.get_recipe(recipe_name)\n    config \u003d recipe.get_settings().get_json_payload()\n    promptStudioId \u003d { \"id\": config[\"associatedPromptStudioId\"], \"prompt_id\": config[\"associatedPromptStudioPromptId\"] }\n    llm_id \u003d config[\"llmId\"]\n    prompt_inputs \u003d config[\"prompt\"][\"textPromptTemplateInputs\"]\n    system_prompt \u003d config[\"prompt\"][\"textPromptSystemTemplate\"]\n    user_prompt \u003d config[\"prompt\"][\"textPromptTemplate\"]\n    temperature \u003d config[\"completionSettings\"][\"temperature\"]\n    for input_def in prompt_inputs:\n        placeholder \u003d f\"{{{{{input_def[\u0027name\u0027]}}}}}\"  # Exemple : {{description}}\n        system_prompt \u003d system_prompt.replace(placeholder, inputs[input_def[\"name\"]])\n        user_prompt \u003d user_prompt.replace(placeholder, inputs[input_def[\"name\"]])\n    llm \u003d project.get_llm(llm_id)\n    completion \u003d llm.new_completion()\n    completion.settings[\"temperature\"] \u003d temperature\n    completion.with_message(system_prompt, role\u003d\u0027system\u0027)\n    completion.with_message(user_prompt, role\u003d\u0027user\u0027)\n    resp \u003d completion.execute()\n    try:\n        return json.loads(resp.text)\n    except:\n        return resp.text\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "query_inputs \u003d {\n    \"role\": \"000\",\n    \"description\" : user_message\n}\nquery \u003d exec_prompt_recipe(agents[\"query\"], query_inputs)\n\nprint(query)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search_nc \u003d exec_prompt_recipe(agents[\"nc_search\"], {\"input\": query})\nsearch_docs \u003d exec_prompt_recipe(agents[\"doc_search\"], {\"input\": query})\nprint(search_docs[\"result\"])\n\n#search_results \u003d []\n#if (query):\n#    search_results \u003d [result for key, value in vector_stores.items() for result in value.similarity_search_with_relevance_scores(query, k\u003d10)]\n#    #print(search_results)\n#   search_results \u003d [ {\n#            \"doc\": doc.metadata[\u0027doc\u0027],\n#            \"chunk_id\": doc.metadata[\u0027chunk_id\u0027],\n#            \"relevance_scores\": score,\n#            \"chunk\": doc.page_content\n#        }\n#        for doc, score in search_results\n#    ]\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "search_results \u003d {\n    key: value.similarity_search(query)\n    for key, value in vector_stores.items()\n}\n\nfor key in KB_IDs:\n    for search_result in search_results[key]:\n        print(f\"# {search_result.doc} \\n{search_result.page_content}\\n\")"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "{\n    \"role\": role,\n    \"description\": user_message,\n    \"search_docs\": doc_search,\n    \"search_nc\": search_nc\n}\n\nresponse_content \u003d exec_prompt_recipe(agents[role], )\n\n\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "response_content \u003d json.loads(resp.text)\ndeep_chat_response \u003d {\n    \"text\": response_content[\u0027comment\u0027],\n    \"label\": response_content[\u0027label\u0027],\n    \"description\": response_content[\u0027description\u0027],\n    \"sources\": search_results,\n    \"role\": \"ai\"\n}\nprint(deep_chat_response)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "auth_info \u003d client.get_auth_info(with_secrets\u003dTrue)\nsecret_value \u003d None\nprint(auth_info[\"secrets\"])\nfor secret in auth_info[\"secrets\"]:\n    if secret[\"key\"] \u003d\u003d \"JWT_SECRET_KEY\":\n        secret_value \u003d secret[\"value\"]\n        break\nprint(secret_value)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}