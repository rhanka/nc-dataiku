{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python in SCW-FA (env markitdown)",
      "language": "python",
      "name": "py-dku-containerized-venv-markitdown-scw-fa"
    },
    "associatedRecipe": "compute_d7DdDueY",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "fabien.antoine@cgi.com"
      },
      "lastModifiedOn": 1741384580258
    },
    "creator": "fabien.antoine@cgi.com",
    "createdOn": 1741384580258,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {}
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import dataiku\n",
        "from mistralai import Mistral\n",
        "from mistralai import DocumentURLChunk, ImageURLChunk, TextChunk\n",
        "import tempfile\n",
        "import base64\n",
        "\n",
        "client \u003d dataiku.api_client()\n",
        "project \u003d client.get_default_project()\n",
        "auth_info \u003d client.get_auth_info(with_secrets\u003dTrue)\n",
        "MISTRAL_API_KEY \u003d None\n",
        "for secret in auth_info[\"secrets\"]:\n",
        "    if secret[\"key\"] \u003d\u003d \"MISTRAL_API_KEY\":\n",
        "        MISTRAL_API_KEY \u003d secret[\"value\"]\n",
        "\n",
        "client \u003d Mistral(api_key\u003dMISTRAL_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Paramétrer le nombre de requêtes parallèles\n",
        "MAX_WORKERS \u003d 10\n",
        "\n",
        "# Folders\n",
        "A220_tech_docs \u003d dataiku.Folder(\"W8lS5GmB\")          # Input folder\n",
        "A220_tech_docs_prep \u003d dataiku.Folder(\"d7DdDueY\")    # Output folder\n",
        "\n",
        "# Lister les fichiers PDF\n",
        "pdf_files \u003d [f for f in A220_tech_docs.list_paths_in_partition() if f.lower().endswith(\".pdf\")]\n",
        "pdf_files.sort()\n",
        "\n",
        "# Lister les fichiers existants\n",
        "existing_files \u003d set(A220_tech_docs_prep.list_paths_in_partition())\n",
        "\n",
        "\n",
        "def extract_md_and_images(json_file_name, response_dict):\n",
        "    base_name \u003d os.path.splitext(json_file_name)[0]\n",
        "\n",
        "    # Extraire et écrire le Markdown\n",
        "    md_file_name \u003d base_name + \".md\"\n",
        "    if md_file_name not in existing_files:\n",
        "        print(f\"Extraction md et images : {md_file_name}\")\n",
        "        markdown_content \u003d \"\\n\\n\".join(page[\"markdown\"] for page in response_dict.get(\"pages\", []))\n",
        "        with A220_tech_docs_prep.get_writer(md_file_name) as writer:\n",
        "            writer.write(markdown_content.encode(\u0027utf-8\u0027))\n",
        "    else:\n",
        "        print(f\"{md_file_name} existe déjà.\")\n",
        "\n",
        "    # Extraire et écrire les images\n",
        "    for page in response_dict.get(\"pages\", []):\n",
        "        for image in page.get(\"images\", []):\n",
        "            image_file_name \u003d base_name + \"-\" + image[\"id\"]\n",
        "            if image_file_name not in existing_files:\n",
        "                image_data \u003d image[\"image_base64\"].split(\",\")[1]\n",
        "                with A220_tech_docs_prep.get_writer(image_file_name) as writer:\n",
        "                    writer.write(base64.b64decode(image_data))\n",
        "\n",
        "\n",
        "\n",
        "def process_pdf(pdf_file):\n",
        "    json_file_name \u003d os.path.splitext(pdf_file)[0] + \".json\"\n",
        "\n",
        "    # Vérifier si le JSON existe déjà\n",
        "    if json_file_name in existing_files:\n",
        "        print(f\"{json_file_name} existe déjà.\")\n",
        "\n",
        "        # Charger le JSON existant pour extraction MD et images\n",
        "        with A220_tech_docs_prep.get_download_stream(json_file_name) as reader:\n",
        "            response_dict \u003d json.load(reader)\n",
        "            extract_md_and_images(json_file_name, response_dict)\n",
        "        return\n",
        "\n",
        "    # Lire le contenu PDF\n",
        "    with A220_tech_docs.get_download_stream(pdf_file) as f:\n",
        "        print(f\"Traitement du fichier : {pdf_file}\")\n",
        "        try:\n",
        "            uploaded_file \u003d client.files.upload(\n",
        "                file\u003d{\n",
        "                    \"file_name\": pdf_file,\n",
        "                    \"content\": f.read(),\n",
        "                },\n",
        "                purpose\u003d\"ocr\",\n",
        "            )\n",
        "            signed_url \u003d client.files.get_signed_url(file_id\u003duploaded_file.id, expiry\u003d1)\n",
        "            pdf_response \u003d client.ocr.process(\n",
        "                document\u003dDocumentURLChunk(document_url\u003dsigned_url.url),\n",
        "                model\u003d\"mistral-ocr-latest\",\n",
        "                include_image_base64\u003dTrue\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur lors du traitement de {pdf_file}: {e}. Réessai dans 2 secondes.\")\n",
        "            time.sleep(2)\n",
        "            try:\n",
        "                pdf_response \u003d client.ocr.process(\n",
        "                    document\u003dDocumentURLChunk(document_url\u003dsigned_url.url),\n",
        "                    model\u003d\"mistral-ocr-latest\",\n",
        "                    include_image_base64\u003dTrue\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"Échec répété pour {pdf_file}, réessai plus tard: {e}\")\n",
        "                return pdf_file  # à réessayer plus tard\n",
        "\n",
        "        response_dict \u003d json.loads(pdf_response.json())\n",
        "        json_string \u003d json.dumps(response_dict, indent\u003d4)\n",
        "\n",
        "        # Écrire le fichier .json\n",
        "        with A220_tech_docs_prep.get_writer(json_file_name) as writer:\n",
        "            writer.write(json_string.encode(\u0027utf-8\u0027))\n",
        "\n",
        "        # Extraire Markdown et images\n",
        "        extract_md_and_images(json_file_name, response_dict)\n",
        "\n",
        "\n",
        "pending_files \u003d pdf_files\n",
        "while pending_files:\n",
        "    retry_files \u003d []\n",
        "    with ThreadPoolExecutor(max_workers\u003dMAX_WORKERS) as executor:\n",
        "        futures \u003d {executor.submit(process_pdf, pdf): pdf for pdf in pending_files}\n",
        "        for future in as_completed(futures):\n",
        "            result \u003d future.result()\n",
        "            if result:\n",
        "                retry_files.append(result)\n",
        "\n",
        "    pending_files \u003d retry_files"
      ]
    }
  ]
}