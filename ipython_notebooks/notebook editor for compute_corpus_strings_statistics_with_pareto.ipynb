{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-markitdown",
      "display_name": "Python (env markitdown)",
      "language": "python"
    },
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "associatedRecipe": "compute_corpus_strings_statistics_with_pareto",
    "creator": "ludovic.bocken@cgi.com",
    "createdOn": 1738598298893,
    "customFields": {},
    "tags": [
      "recipe-editor"
    ],
    "modifiedBy": "ludovic.bocken@cgi.com"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nimport pandas as pd\nimport numpy as np\nfrom dataiku import pandasutils as pdu\n\n# Read recipe inputs\nA220_tech_docs_text \u003d dataiku.Folder(\"rhnW9xGx\")\nA220_tech_docs_text_info \u003d A220_tech_docs_text.get_info()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nimport pandas as pd\nimport numpy as np\nfrom dataiku import pandasutils as pdu\nimport re\n\n# Read recipe inputs\nA220_tech_docs_text \u003d dataiku.Folder(\"rhnW9xGx\")\nA220_tech_docs_text_info \u003d A220_tech_docs_text.get_info()\n\n# Function to read the corpus from the folder and extract strings\ndef read_corpus(folder):\n    corpus \u003d []\n    for file_path in folder.list_paths_in_partition():\n        with folder.get_download_stream(file_path) as f:\n            text \u003d f.read().decode(\u0027utf-8\u0027)\n            # Split text into words, convert to lowercase, and filter out any words containing numbers\n            words \u003d text.split()\n            words \u003d [word.lower() for word in words if not re.search(r\u0027\\d\u0027, word)]\n            corpus.extend(words)\n    return corpus\n\ncorpus \u003d read_corpus(A220_tech_docs_text)\n\n# Compute frequency of each string in the corpus\nfrequency \u003d pd.Series(corpus).value_counts().reset_index()\nfrequency.columns \u003d [\u0027string\u0027, \u0027frequency\u0027]\n\n# Calculate relative frequency\ntotal_count \u003d frequency[\u0027frequency\u0027].sum()\nfrequency[\u0027relative_frequency\u0027] \u003d frequency[\u0027frequency\u0027] / total_count\n\n# Rank the strings by frequency\nfrequency[\u0027rank\u0027] \u003d frequency[\u0027frequency\u0027].rank(method\u003d\u0027min\u0027, ascending\u003dFalse)\n\n# Sort by string in ascending order before calculating cumulative sum\nfrequency \u003d frequency.sort_values(by\u003d\u0027frequency\u0027, ascending\u003dFalse)\n\n# Calculate cumulative sum of frequencies\nfrequency[\u0027cumulative_sum\u0027] \u003d frequency[\u0027frequency\u0027].cumsum()\n\n# Calculate pareto as cumulative_sum percentage\nfrequency[\u0027pareto\u0027] \u003d (frequency[\u0027cumulative_sum\u0027] / total_count) * 100\n\n# Compute recipe outputs\ncorpus_strings_statistics_with_pareto_df \u003d frequency"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "corpus_strings_statistics_with_pareto_df"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Write recipe outputs\ncorpus_strings_statistics_with_pareto \u003d dataiku.Dataset(\"corpus_strings_statistics_with_pareto\")\ncorpus_strings_statistics_with_pareto.write_with_schema(corpus_strings_statistics_with_pareto_df)"
      ],
      "outputs": []
    }
  ]
}