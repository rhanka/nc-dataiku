{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-containerized-venv-markitdown-scw-fa",
      "display_name": "Python in SCW-FA (env markitdown)",
      "language": "python"
    },
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.11.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "createdOn": 1735315006284,
    "associatedRecipe": "compute_a220_tech_docs_content",
    "customFields": {},
    "dkuGit": {
      "lastInteraction": 0
    },
    "creator": "fabien.antoine@cgi.com",
    "tags": [
      "recipe-editor"
    ],
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "fabien.antoine@cgi.com"
      },
      "lastModifiedOn": 1735315006284
    },
    "modifiedBy": "fabien.antoine@cgi.com"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nimport io\nimport pandas as pd\nimport re\nimport os\nimport json\n\n# Définir les dossiers d\u0027entrée et de sortie\npdf_folder \u003d dataiku.Folder(\"W8lS5GmB\")  # Dossier contenant les PDF originaux\nmd_folder \u003d dataiku.Folder(\"d7DdDueY\")   # Dossier contenant les annotations générées\n\n# Lister les fichiers PDF\npdf_files \u003d [f for f in pdf_folder.list_paths_in_partition() if f.lower().endswith(\".pdf\")]\npdf_files.sort()\n\n# Fonction pour lire le contenu d\u0027un fichier s\u0027il existe\ndef read_file_content(folder, file_path):\n    if file_path in folder.list_paths_in_partition():\n        with folder.get_download_stream(file_path) as stream:\n            return io.BytesIO(stream.read()).read().decode(\"utf-8\")\n    return None\n\n# Initialiser le dictionnaire pour stocker les données\ndata \u003d {\n    \"doc\": [],             # Nom complet du PDF avec la page\n    \"doc_root\": [],        # Nom du PDF sans la page\n    \"json\": [],            # Contenu JSON\n    \"md\": [],              # Contenu Markdown\n    \"md_img\": [],          # Contenu Markdown avec descriptions d\u0027images\n    \"json_img\": []         # Contenu JSON avec descriptions d\u0027images\n}\n\n# Pour chaque PDF, extraire toutes les annotations associées\nfor pdf_file in pdf_files:\n    # Extraire le nom de base du document (sans l\u0027extension)\n    base_name \u003d os.path.splitext(pdf_file)[0]\n    doc_root \u003d base_name.split(\u0027_page_\u0027)[0] if \u0027_page_\u0027 in base_name else base_name\n    \n    # Chemins des fichiers d\u0027annotation\n    json_file \u003d base_name + \".json\"\n    md_file \u003d base_name + \".md\"\n    md_img_file \u003d base_name + \"__with_img_desc.md\"\n    json_img_file \u003d base_name + \"__with_img_desc.json\"\n    \n    # Lire le contenu des fichiers d\u0027annotation\n    json_content \u003d read_file_content(md_folder, json_file)\n    md_content \u003d read_file_content(md_folder, md_file)\n    md_img_content \u003d read_file_content(md_folder, md_img_file)\n    json_img_content \u003d read_file_content(md_folder, json_img_file)\n    \n    # Identifier les images associées au document\n    img_pattern \u003d re.compile(rf\"^{re.escape(base_name)}-img-(\\d+)\\.jpeg$\")\n    all_files \u003d md_folder.list_paths_in_partition()\n    \n    # Créer un dictionnaire pour stocker les informations sur les images\n    images \u003d {}\n    \n    # Chercher toutes les images et leurs descriptions\n    for file_path in all_files:\n        img_match \u003d img_pattern.match(file_path)\n        if img_match:\n            img_num \u003d img_match.group(1)\n            img_key \u003d f\"img-{img_num}\"\n            desc_file \u003d f\"{base_name}-img-{img_num}.md\"\n            \n            # Ajouter l\u0027image et sa description au dictionnaire\n            if img_key not in images:\n                images[img_key] \u003d {\n                    \"path\": file_path,\n                    \"desc\": None\n                }\n            \n            # Vérifier si une description existe pour cette image\n            if desc_file in all_files:\n                img_desc \u003d read_file_content(md_folder, desc_file)\n                images[img_key][\"desc\"] \u003d img_desc\n    \n    # Ajouter les données de base du document\n    row \u003d {\n        \"doc\": pdf_file,\n        \"doc_root\": doc_root + \".pdf\",\n        \"json\": json_content,\n        \"md\": md_content,\n        \"md_img\": md_img_content,\n        \"json_img\": json_img_content\n    }\n    \n    # Ajouter les informations sur les images\n    for img_key, img_info in sorted(images.items()):\n        row[img_key] \u003d img_info[\"path\"]\n        if img_info[\"desc\"]:\n            row[f\"{img_key}-desc\"] \u003d img_info[\"desc\"]\n    \n    # Ajouter la ligne au dataset\n    for key in data:\n        if key in row:\n            data[key].append(row[key])\n        else:\n            data[key].append(None)\n    \n    # Ajouter dynamiquement les colonnes d\u0027images\n    for key in row:\n        if key not in data:\n            data[key] \u003d [None] * (len(data[\"doc\"]) - 1)\n            data[key].append(row[key])\n\n# Créer le DataFrame\ndf \u003d pd.DataFrame.from_dict(data)\n\n# Écrire le DataFrame dans un dataset\ndataiku.Dataset(\"a220_tech_docs_annotations\").write_with_schema(df)\n\nprint(f\"Extraction terminée avec succès. {len(df)} documents traités.\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}