{
  "metadata": {
    "kernelspec": {
      "display_name": "Python in SCW-FA (env markitdown)",
      "language": "python",
      "name": "py-dku-containerized-venv-markitdown-scw-fa"
    },
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "ludovic.bocken@cgi.com"
      },
      "lastModifiedOn": 1738684992090
    },
    "creator": "ludovic.bocken@cgi.com",
    "createdOn": 1738684992090,
    "tags": [
      "deleted-recipe-editor"
    ],
    "customFields": {}
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import dataiku\n",
        "import pandas as pd, numpy as np\n",
        "from dataiku import pandasutils as pdu\n",
        "import spacy\n",
        "\n",
        "# Load spaCy model\n",
        "nlp \u003d spacy.load(\"en_core_web_sm\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read recipe inputs\n",
        "A220_tech_docs_text \u003d dataiku.Folder(\"rhnW9xGx\")\n",
        "A220_tech_docs_text_info \u003d A220_tech_docs_text.get_info()\n",
        "\n",
        "# Assuming the folder contains text files, read them into a DataFrame\n",
        "file_paths \u003d A220_tech_docs_text.list_paths_in_partition()\n",
        "texts \u003d []\n",
        "for file_path in file_paths:\n",
        "    with A220_tech_docs_text.get_download_stream(file_path) as f:\n",
        "        texts.append(f.read().decode(\u0027utf-8\u0027))\n",
        "\n",
        "# Create a DataFrame\n",
        "df \u003d pd.DataFrame({\u0027text\u0027: texts})"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Perform named entity recognition\n",
        "def extract_entities(text):\n",
        "    doc \u003d nlp(text)\n",
        "    entities \u003d [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return entities\n",
        "\n",
        "df[\u0027entities\u0027] \u003d df[\u0027text\u0027].apply(extract_entities)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Convert the DataFrame to the required format\n",
        "named_entity_recognition_df \u003d df.explode(\u0027entities\u0027).dropna().reset_index(drop\u003dTrue)\n",
        "named_entity_recognition_df[[\u0027entity\u0027, \u0027label\u0027]] \u003d pd.DataFrame(named_entity_recognition_df[\u0027entities\u0027].tolist(), index\u003dnamed_entity_recognition_df.index)\n",
        "named_entity_recognition_df \u003d named_entity_recognition_df.drop(columns\u003d[\u0027entities\u0027])"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Write recipe outputs\n",
        "named_entity_recognition \u003d dataiku.Dataset(\"named_entity_recognition\")\n",
        "named_entity_recognition.write_with_schema(named_entity_recognition_df)"
      ],
      "outputs": []
    }
  ]
}