{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python in SCW-FA (env markitdown)",
      "language": "python",
      "name": "py-dku-containerized-venv-markitdown-scw-fa"
    },
    "associatedRecipe": "compute_a220_tech_docs_content",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "fabien.antoine@cgi.com"
      },
      "lastModifiedOn": 1735315006284
    },
    "creator": "fabien.antoine@cgi.com",
    "createdOn": 1735315006284,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {}
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "import dataiku\n",
        "import io\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain.text_splitter import (\n",
        "    RecursiveCharacterTextSplitter,\n",
        "    MarkdownHeaderTextSplitter,\n",
        ")\n",
        "\n",
        "\n",
        "pdf_folder \u003d dataiku.Folder(\"W8lS5GmB\")\n",
        "md_folder \u003d dataiku.Folder(\"d7DdDueY\")\n",
        "\n",
        "pdf_files \u003d [f for f in pdf_folder.list_paths_in_partition() if f.lower().endswith(\".pdf\")]\n",
        "pdf_files.sort()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "headers \u003d [\n",
        "    (\"#\", \"h1\"),\n",
        "    (\"##\", \"h2\"),\n",
        "    (\"###\", \"h3\"),\n",
        "    (\"####\", \"h4\"),\n",
        "    (\"#####\", \"h5\")\n",
        "]\n",
        "\n",
        "md_splitter \u003d MarkdownHeaderTextSplitter(\n",
        "    headers_to_split_on\u003dheaders\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "text_splitter \u003d RecursiveCharacterTextSplitter(chunk_size\u003d1000, chunk_overlap\u003d200)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "d \u003d {\"chunk\": [], \"doc\": []}\n",
        "\n",
        "for path in pdf_files:\n",
        "    doc \u003d path[1:].replace(\"\u003d\", \"/\")\n",
        "    with folder.get_download_stream(path) as stream:\n",
        "        s \u003d io.BytesIO(stream.read()).read().decode(\"utf-8\")\n",
        "        result \u003d text_splitter.split_documents(md_splitter.split_text(s))\n",
        "\n",
        "    for i in range(len(result)):\n",
        "        header \u003d \" \u003e \".join(\n",
        "            [\n",
        "                result[i].metadata[k[1]].replace(\"#\", \"\").strip()\n",
        "                for k in headers\n",
        "                if k[1] in result[i].metadata\n",
        "                if result[i].metadata[k[1]] is not None\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        d[\"chunk\"].append((header + \"\\n\\n\" + result[i].page_content).strip())\n",
        "        d[\"doc\"].append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "df \u003d pd.DataFrame.from_dict(d)\n",
        "df[\"chunk_id\"] \u003d range(len(df))\n",
        "dataiku.Dataset(\"a220_tech_docs_content\").write_with_schema(df)"
      ]
    }
  ]
}