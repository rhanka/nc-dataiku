{
  "metadata": {
    "kernelspec": {
      "display_name": "Python (env markitdown)",
      "language": "python",
      "name": "py-dku-venv-markitdown"
    },
    "creator": "fabien.antoine@cgi.com",
    "createdOn": 1735622424502,
    "tags": [],
    "customFields": {}
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from dataiku.langchain.dku_llm import DKUChatLLM\n",
        "\n",
        "KB_ID \u003d \"zQ92IhQ9\"\n",
        "\n",
        "client \u003d dataiku.api_client()\n",
        "project \u003d client.get_default_project()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Listing available LLMs\n",
        "llm_list \u003d project.list_llms()\n",
        "\n",
        "for llm in llm_list:\n",
        "    print(f\"- {llm.description} (id: {llm.id})\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fill with your LLM id\n",
        "LLM_ID \u003d \"XXXXX\""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Preparing the Knowledge Bank, Vector store and LLM\n",
        "kb \u003d dataiku.KnowledgeBank(id\u003dKB_ID, project_key\u003dproject.project_key)\n",
        "vector_store \u003d kb.as_langchain_vectorstore()\n",
        "gpt_lc \u003d DKUChatLLM(llm_id\u003dLLM_ID, temperature\u003d0)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create the question answering chain\n",
        "chain \u003d load_qa_chain(gpt_lc, chain_type\u003d\"stuff\")\n",
        "query \u003d \"What will inflation in Europe look like and why?\"\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Performing semantic (vector) search\n",
        "search_results \u003d vector_store.similarity_search(query)\n",
        "\n",
        "for search_result in search_results:\n",
        "    print(f\"- {search_result.page_content}\\n\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ⚡ Get the results ⚡\n",
        "resp \u003d chain({\"input_documents\":search_results, \"question\": query})\n",
        "print(resp[\"output_text\"])"
      ],
      "outputs": []
    }
  ]
}